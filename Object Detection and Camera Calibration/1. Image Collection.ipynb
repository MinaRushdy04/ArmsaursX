{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Images to Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['small_yellow_cube','medium_yellow_cube','big_yellow_cube','small_red_cube','medium_red_cube','big_red_cube']\n",
    "number_imgs = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {IMAGES_PATH}\n",
    "    if os.name == 'nt':\n",
    "         !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH, label, label + '.' + '{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "classes = ['small_yellow_cube','medium_yellow_cube','big_yellow_cube','small_red_cube','medium_red_cube','big_red_cube']  \n",
    "\n",
    "input_dir = \"Tensorflow/workspace/images/collectedimages\"\n",
    "output_dir = \"dataset\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(os.path.join(output_dir, \"images\"))\n",
    "    os.makedirs(os.path.join(output_dir, \"labels\"))\n",
    "\n",
    "for label in classes:\n",
    "    img_dir = os.path.join(input_dir, label)\n",
    "    for file in tqdm(os.listdir(img_dir)):\n",
    "        if file.endswith(\".xml\"):\n",
    "            xml_path = os.path.join(img_dir, file)\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            img_name = root.find(\"filename\").text\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "\n",
    "            shutil.copy(img_path, os.path.join(output_dir, \"images\", img_name))\n",
    "\n",
    "            w = int(root.find(\"size/width\").text)\n",
    "            h = int(root.find(\"size/height\").text)\n",
    "\n",
    "            txt_path = os.path.join(output_dir, \"labels\", img_name.replace(\".jpg\", \".txt\"))\n",
    "            with open(txt_path, \"w\") as f:\n",
    "                for obj in root.findall(\"object\"):\n",
    "                    cls = obj.find(\"name\").text\n",
    "                    cls_id = classes.index(cls)\n",
    "\n",
    "                    xmlbox = obj.find(\"bndbox\")\n",
    "                    xmin = int(xmlbox.find(\"xmin\").text)\n",
    "                    ymin = int(xmlbox.find(\"ymin\").text)\n",
    "                    xmax = int(xmlbox.find(\"xmax\").text)\n",
    "                    ymax = int(xmlbox.find(\"ymax\").text)\n",
    "\n",
    "                    # YOLO format: x_center y_center width height (normalized)\n",
    "                    x_center = (xmin + xmax) / 2.0 / w\n",
    "                    y_center = (ymin + ymax) / 2.0 / h\n",
    "                    bw = (xmax - xmin) / w\n",
    "                    bh = (ymax - ymin) / h\n",
    "\n",
    "                    f.write(f\"{cls_id} {x_center} {y_center} {bw} {bh}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import glob, shutil\n",
    "\n",
    "images = glob.glob(\"dataset/images/*.jpg\")\n",
    "labels = glob.glob(\"dataset/labels/*.txt\")\n",
    "\n",
    "train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "def move_files(file_list, target_img_dir, target_lbl_dir):\n",
    "    os.makedirs(target_img_dir, exist_ok=True)\n",
    "    os.makedirs(target_lbl_dir, exist_ok=True)\n",
    "    for img in file_list:\n",
    "        lbl = img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "        shutil.copy(img, target_img_dir)\n",
    "        shutil.copy(lbl, target_lbl_dir)\n",
    "\n",
    "move_files(train_imgs, \"dataset/images/train\", \"dataset/labels/train\")\n",
    "move_files(val_imgs, \"dataset/images/val\", \"dataset/labels/val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"nc: 6\n",
    "path: D:/YOLO Object Detection/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "names:\n",
    "  0: small_yellow_cube\n",
    "  1: medium_yellow_cube\n",
    "  2: big_yellow_cube\n",
    "  3: small_red_cube\n",
    "  4: medium_red_cube\n",
    "  5: big_red_cube\n",
    "\"\"\"\n",
    "\n",
    "with open(\"dataset/dataset.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"dataset.yaml created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo train data=dataset/dataset.yaml model=yolov8n.pt epochs=100 imgsz=320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Extract real coordinates of objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should run camera_calibration.ipynb to know parameters such as camera_matix, dist_coeffs, R_cam, t_cam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "CAP_INDEX = 1\n",
    "\n",
    "camera_matrix = np.array([[546.25061067,   0.,         317.92410558],\n",
    "                          [  0.,         548.85987516, 239.71830120],\n",
    "                          [  0.,           0.,           1.        ]])\n",
    "\n",
    "dist_coeffs = np.array([[ 0.23208356, -1.03167154, -0.00369298, -0.00400159, 2.99040251]])\n",
    "\n",
    "R_cam = np.array([[ 0.99418228,  0.03701466, -0.10115093],\n",
    "                  [-0.03531900,  0.99920477,  0.01850404],\n",
    "                  [ 0.10175541, -0.01482384,  0.99469899]])\n",
    "\n",
    "t_cam = np.array([[-1.98635758],\n",
    "                  [-1.26039358],\n",
    "                  [ 6.79782214]])\n",
    "\n",
    "DIST_THRESH = 50  \n",
    "\n",
    "SCALE_FACTOR = 2.4   # adjust based on real-world measurements\n",
    "\n",
    "#To verify that the coordinates are correct, we compare the real-world distance between two points with the distance between the corresponding points in the image\n",
    "#If they are not equal -> Do scaling \n",
    "\n",
    "cap = cv2.VideoCapture(CAP_INDEX)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Cannot open camera {CAP_INDEX}\")\n",
    "\n",
    "object_id = 0\n",
    "centers = {}\n",
    "\n",
    "def pixel_to_world(u_px, v_px, K, dist, R, t):\n",
    "    pts = np.array([[[u_px, v_px]]], dtype=np.float32)\n",
    "    und = cv2.undistortPoints(pts, K, dist, P=K)\n",
    "    u_corr, v_corr = und[0,0]\n",
    "\n",
    "    p = np.array([u_corr, v_corr, 1.0]).reshape(3,1)\n",
    "    M = K @ R[:, :2]\n",
    "    b = K @ t\n",
    "\n",
    "    A = np.hstack((M, -p))\n",
    "    rhs = -b\n",
    "\n",
    "    try:\n",
    "        sol = np.linalg.solve(A, rhs)\n",
    "    except np.linalg.LinAlgError:\n",
    "        sol, *_ = np.linalg.lstsq(A, rhs, rcond=None)\n",
    "\n",
    "    X = float(sol[0]) * SCALE_FACTOR\n",
    "    Y = float(sol[1]) * SCALE_FACTOR\n",
    "    s = float(sol[2])\n",
    "\n",
    "    return X, Y, s, (u_corr, v_corr)\n",
    "\n",
    "def worldXY_to_cameraXYZ(X_world, Y_world, R, t):\n",
    "    Pw = np.array([[X_world], [Y_world], [0.0]])\n",
    "    Pc = R @ Pw + t\n",
    "    return float(Pc[0]), float(Pc[1]), float(Pc[2])\n",
    "\n",
    "print(\"Starting capture. Press 'q' to quit.\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"No frame, exiting\")\n",
    "        break\n",
    "\n",
    "    im_h, im_w = frame.shape[:2]\n",
    "    results = model(frame)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            cx = int((x1 + x2) / 2)\n",
    "            cy = int((y1 + y2) / 2)\n",
    "\n",
    "            found = None\n",
    "            for oid, (px, py) in centers.items():\n",
    "                if abs(cx - px) < DIST_THRESH and abs(cy - py) < DIST_THRESH:\n",
    "                    found = oid\n",
    "                    break\n",
    "            if found is None:\n",
    "                object_id += 1\n",
    "                found = object_id\n",
    "            centers[found] = (cx, cy)\n",
    "\n",
    "            Xw, Yw, scale_s, (u_corr, v_corr) = pixel_to_world(cx, cy, camera_matrix, dist_coeffs, R_cam, t_cam)\n",
    "            Xc, Yc, Zc = worldXY_to_cameraXYZ(Xw, Yw, R_cam, t_cam)\n",
    "\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "            cv2.circle(frame, (cx, cy), 5, (0,0,255), -1)\n",
    "            cv2.line(frame, (0, cy), (im_w, cy), (0,0,255), 1)\n",
    "            cv2.line(frame, (cx, 0), (cx, im_h), (0,0,255), 1)\n",
    "\n",
    "            txt = f\"ID:{found} ({cx},{cy}) class:{model.names[cls]} conf:{conf:.2f}\"\n",
    "            world_txt = f\"World(X,Y): {Xw:.2f}, {Yw:.2f}\"\n",
    "            cam_txt = f\"CamXYZ: {Xc:.2f}, {Yc:.2f}, {Zc:.2f}\"\n",
    "\n",
    "            cv2.putText(frame, txt, (x1, y1-30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
    "            cv2.putText(frame, world_txt, (x1, y1-14), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 1)\n",
    "            cv2.putText(frame, cam_txt, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (200,200,200), 1)\n",
    "\n",
    "            print(f\"ID {found} | pixel=({cx},{cy}) undist=({u_corr:.1f},{v_corr:.1f}) | \"\n",
    "                  f\"World(X,Y)=({Xw:.3f},{Yw:.3f}) | CamXYZ=({Xc:.3f},{Yc:.3f},{Zc:.3f})\")\n",
    "\n",
    "    cv2.imshow(\"YOLO + Calibration -> World coords\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
